import streamlit as st
from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline

# Configuration de la page
st.set_page_config(page_title="Analyse de sentiment", page_icon="üí¨")
st.title("üí¨ Analyse de sentiment des avis clients (CamemBERT)")
st.write("Entrez un avis en fran√ßais pour d√©terminer s‚Äôil est **positif** ou **n√©gatif**.")

# Chargement du mod√®le avec mise en cache
@st.cache_resource
def load_model():
    try:
        model_name = "tblard/tf-allocine"
        tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)
        model = AutoModelForSequenceClassification.from_pretrained(model_name, from_tf=True)
        return pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)
    except Exception as e:
        st.error(f"Erreur lors du chargement du mod√®le : {e}")
        return None

# Zone de saisie utilisateur
user_input = st.text_area("‚úçÔ∏è Votre avis ici :", height=150)

# Bouton d'analyse
if st.button("Analyser le sentiment"):
    if user_input.strip():
        sentiment_pipeline = load_model()
        if sentiment_pipeline:
            with st.spinner("üîç Analyse en cours..."):
                result = sentiment_pipeline(user_input)[0]
                label = result["label"]
                score = round(result["score"] * 100, 2)

                st.markdown("### üìä R√©sultat de l'analyse")
                if label.upper() == "POSITIVE":
                    st.success(f"‚úÖ Sentiment d√©tect√© : Positif ({score}%)")
                else:
                    st.error(f"‚ö†Ô∏è Sentiment d√©tect√© : N√©gatif ({score}%)")

                st.progress(score / 100)
                st.write(f"**Confiance du mod√®le** : {score}%")
        else:
            st.warning("Le mod√®le n'a pas pu √™tre charg√©.")
    else:
        st.warning("Veuillez entrer un texte √† analyser.")
