import streamlit as st
from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline

# Configuration
st.set_page_config(page_title="Analyse de sentiment", page_icon="üí¨")
st.title("üí¨ Analyse de sentiment (XLM-Roberta)")
st.write("Entrez un avis en fran√ßais pour d√©terminer s‚Äôil est **positif**, **n√©gatif** ou **neutre**.")

# Chargement du mod√®le
@st.cache_resource
def load_model():
    try:
        model_name = "cardiffnlp/twitter-xlm-roberta-base-sentiment"
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSequenceClassification.from_pretrained(model_name)
        return pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)
    except Exception as e:
        st.error(f"Erreur lors du chargement du mod√®le : {e}")
        return None

# Zone de saisie
user_input = st.text_area("‚úçÔ∏è Votre avis ici :", height=150)

if st.button("Analyser le sentiment"):
    if user_input.strip():
        sentiment_pipeline = load_model()
        if sentiment_pipeline:
            with st.spinner("Analyse en cours..."):
                result = sentiment_pipeline(user_input)[0]
                label = result["label"]
                score = round(result["score"] * 100, 2)

                st.markdown("### üìä R√©sultat de l'analyse")
                st.write(f"**Sentiment d√©tect√©** : {label}")
                st.progress(score / 100)
                st.write(f"**Confiance du mod√®le** : {score}%")
        else:
            st.warning("Le mod√®le n‚Äôa pas pu √™tre charg√©.")
    else:
        st.warning("Veuillez entrer un texte.")

